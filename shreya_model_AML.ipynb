{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shreya-model-AML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7o1IJs29aufd0Y1V2wK7V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vspvikram/AML_project/blob/main/shreya_model_AML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcf9uqFX0HC-",
        "outputId": "7e21a70d-576c-4025-a02e-babf19bc7e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import datetime\n",
        "import time\n",
        "import re\n",
        "import functools\n",
        "import zipfile\n",
        "\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "import string\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQN6oHbl0h4Z",
        "outputId": "f37765ce-e63c-4d7e-976a-ebe60cf8fe98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/train.csv')  \n",
        "test = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/test.csv') \n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "6Kq0fIcM14fk",
        "outputId": "9d5c88af-b4fd-4c73-9db4-8e239a908f6f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image1</th>\n",
              "      <th>Image2</th>\n",
              "      <th>Caption</th>\n",
              "      <th>Number</th>\n",
              "      <th>Clean_capt</th>\n",
              "      <th>Caption_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CXR588_IM-2183-1001</td>\n",
              "      <td>CXR588_IM-2183-2001</td>\n",
              "      <td>No acute cardiopulmonary abnormalities.</td>\n",
              "      <td>831</td>\n",
              "      <td>no acute cardiopulmonary abnormality</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CXR2937_IM-1339-1001</td>\n",
              "      <td>CXR2937_IM-1339-2001</td>\n",
              "      <td>No acute cardiopulmonary findings.</td>\n",
              "      <td>396</td>\n",
              "      <td>no acute cardiopulmonary finding</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CXR255_IM-1058-1001</td>\n",
              "      <td>CXR255_IM-1058-2001</td>\n",
              "      <td>No acute cardiopulmonary disease.</td>\n",
              "      <td>2281</td>\n",
              "      <td>no acute cardiopulmonary disease</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CXR1679_IM-0448-1001</td>\n",
              "      <td>CXR1679_IM-0448-1002</td>\n",
              "      <td>Normal chest</td>\n",
              "      <td>1779</td>\n",
              "      <td>normal chest</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CXR2660_IM-1142-1001</td>\n",
              "      <td>CXR2660_IM-1142-2001</td>\n",
              "      <td>Normal chest</td>\n",
              "      <td>518</td>\n",
              "      <td>normal chest</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Image1  ... Caption_count\n",
              "0   CXR588_IM-2183-1001  ...           117\n",
              "1  CXR2937_IM-1339-1001  ...           118\n",
              "2   CXR255_IM-1058-1001  ...           105\n",
              "3  CXR1679_IM-0448-1001  ...            36\n",
              "4  CXR2660_IM-1142-1001  ...            36\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train['Number'].unique()))\n",
        "print(len(train['Number']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2Rt3kZ2siBe",
        "outputId": "f900ccdc-21a0-4771-e1e5-004c3684d027"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3086\n",
            "3214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip \"/content/gdrive/MyDrive/Colab Notebooks/image.zip\" -d \"/content/gdrive/MyDrive/Colab Notebooks/image/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIe59ubOSe31",
        "outputId": "793b601c-144a-4562-f212-b0aef62a43f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/Colab Notebooks/image.zip\n",
            "replace /content/gdrive/MyDrive/Colab Notebooks/image/CXR163_IM-0410-12012.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "model = InceptionV3(weights='imagenet')\n",
        "model_new = Model(model.input, model.layers[-2].output)\n",
        "for layer in model_new.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "'''\n",
        "def preprocess(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x\n",
        "\n",
        "def encode(image):\n",
        "    image = preprocess(image) \n",
        "    fea_vec = model_new.predict(image) \n",
        "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1])\n",
        "    return fea_vec\n",
        "\n",
        "encoding_train = {}\n",
        "for img in train_img:\n",
        "    encoding_train[img[len(images_path):]] = encode(img)\n",
        "train_features = encoding_train\n",
        "\n",
        "encoding_test = {}\n",
        "for img in test_img:\n",
        "    encoding_test[img[len(images_path):]] = encode(img)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "OPOiKOJHcoaE",
        "outputId": "5ade257c-4686-4e57-e764-cfe81e5fdc15"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef preprocess(image_path):\\n    img = image.load_img(image_path, target_size=(224, 224))\\n    x = image.img_to_array(img)\\n    x = np.expand_dims(x, axis=0)\\n    x = preprocess_input(x)\\n    return x\\n\\ndef encode(image):\\n    image = preprocess(image) \\n    fea_vec = model_new.predict(image) \\n    fea_vec = np.reshape(fea_vec, fea_vec.shape[1])\\n    return fea_vec\\n\\nencoding_train = {}\\nfor img in train_img:\\n    encoding_train[img[len(images_path):]] = encode(img)\\ntrain_features = encoding_train\\n\\nencoding_test = {}\\nfor img in test_img:\\n    encoding_test[img[len(images_path):]] = encode(img)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_features(df, input_size):\n",
        "    path = '/content/gdrive/MyDrive/Colab Notebooks/image/'\n",
        "    \n",
        "    Xnet_features = pd.DataFrame(columns=['Number','features'])\n",
        "    pos = 0\n",
        "    for i in range(len(df)):\n",
        "        f = os.path.join(path, df.iloc[i][\"Image1\"].lstrip())\n",
        "        f = f+\".png\"\n",
        "        #image1 = Image.open(f)\n",
        "        img1 = image.load_img(f, target_size=(299, 299))\n",
        "        x1 = image.img_to_array(img1)\n",
        "        x1 = np.expand_dims(x1, axis=0)\n",
        "        x1 = preprocess_input(x1)\n",
        "        \n",
        "        f = os.path.join(path, df.iloc[i][\"Image2\"].lstrip())\n",
        "        f = f+\".png\"\n",
        "        \n",
        "        img2 = image.load_img(f, target_size=(299, 299))\n",
        "        x2 = image.img_to_array(img2)\n",
        "        x2 = np.expand_dims(x2, axis=0)\n",
        "        x2 = preprocess_input(x2)\n",
        "\n",
        "        #image2 = Image.open(f)\n",
        "        \n",
        "        def encode(image):\n",
        "            fea_vec = model_new.predict(image) \n",
        "            #fea_vec = np.reshape(fea_vec, fea_vec.shape[1])\n",
        "            return fea_vec\n",
        "\n",
        "        image1_features = encode(x1)\n",
        "        image2_features = encode(x2)\n",
        "        input_concat = np.concatenate((image1_features, image2_features), axis=1)\n",
        "        \n",
        "        Xnet_features.loc[pos] = [int(df.iloc[i]['Number']),input_concat]\n",
        "        pos=pos+1\n",
        "    return Xnet_features"
      ],
      "metadata": {
        "id": "d9z_EWQG2dOD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = {}\n",
        "a[12]='apple'\n",
        "a[12]='ball'\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHcYHcFGszZK",
        "outputId": "19620d14-197b-482e-fbcb-562ded11eef5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{12: 'ball'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_output = get_img_features(train.iloc[0:40,], (299,299,3))\n",
        "en_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lwZEt1XO48IR",
        "outputId": "29efcb49-9acb-44b2-9eab-2736c700636d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>831</td>\n",
              "      <td>[[0.37776634, 0.37836018, 0.082196, 0.2683568,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>396</td>\n",
              "      <td>[[0.5769105, 0.30342862, 0.15529898, 0.3956436...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2281</td>\n",
              "      <td>[[0.2971441, 0.35165608, 0.04101849, 0.3135675...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1779</td>\n",
              "      <td>[[0.61468536, 0.39148712, 0.2238153, 0.2804152...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518</td>\n",
              "      <td>[[0.45647693, 0.32283726, 0.23408943, 0.260987...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3746</td>\n",
              "      <td>[[0.13502342, 0.4192431, 0.08697965, 0.2309943...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>472</td>\n",
              "      <td>[[0.64468104, 0.7292648, 0.22713414, 0.3975431...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>80</td>\n",
              "      <td>[[0.58057076, 0.33272293, 0.22853439, 0.198079...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>316</td>\n",
              "      <td>[[0.9567922, 0.12568782, 0.073065616, 0.208439...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1810</td>\n",
              "      <td>[[0.65189403, 0.24754304, 0.12505412, 0.369573...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>342</td>\n",
              "      <td>[[0.9839933, 0.39295018, 0.16886151, 0.4594364...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1245</td>\n",
              "      <td>[[0.471568, 0.12150279, 0.06463521, 0.3586164,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2871</td>\n",
              "      <td>[[0.39337683, 0.28769162, 0.28371662, 0.569816...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>676</td>\n",
              "      <td>[[0.6500033, 0.021736195, 0.20317031, 0.216475...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2913</td>\n",
              "      <td>[[0.18810251, 0.57685196, 0.29657072, 0.195130...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3231</td>\n",
              "      <td>[[0.78989106, 0.4417708, 0.07042155, 0.3457232...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1883</td>\n",
              "      <td>[[0.6578378, 0.41649896, 0.3062988, 0.23542085...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>952</td>\n",
              "      <td>[[0.49812648, 0.33461848, 0.15921214, 0.261522...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1443</td>\n",
              "      <td>[[0.38634288, 0.84911853, 0.31505927, 0.402687...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3108</td>\n",
              "      <td>[[0.37978047, 0.43206847, 0.31043005, 0.256928...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3324</td>\n",
              "      <td>[[0.7050163, 0.20532523, 0.14971204, 0.2283516...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1123</td>\n",
              "      <td>[[0.67499614, 0.36101168, 0.04689063, 0.442935...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>50</td>\n",
              "      <td>[[0.45654327, 0.20786308, 0.30018467, 0.509915...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1802</td>\n",
              "      <td>[[0.8868337, 0.09538166, 0.20751624, 0.2968963...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3175</td>\n",
              "      <td>[[0.2584805, 0.32244095, 0.15219368, 0.0984607...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>934</td>\n",
              "      <td>[[0.47341016, 0.409316, 0.06726379, 0.17145704...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1599</td>\n",
              "      <td>[[0.19334601, 0.5033514, 0.36038828, 0.2101330...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2448</td>\n",
              "      <td>[[0.3886888, 0.036727108, 0.077027924, 0.41263...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1840</td>\n",
              "      <td>[[0.30242607, 0.46671247, 0.13435742, 0.402290...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3111</td>\n",
              "      <td>[[0.6123928, 0.1493933, 0.098767206, 0.032874,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>3730</td>\n",
              "      <td>[[0.27804264, 0.5632236, 0.19547863, 0.2612163...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>189</td>\n",
              "      <td>[[0.71878177, 0.2273899, 0.17426203, 0.3704720...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3300</td>\n",
              "      <td>[[0.6020217, 0.11465368, 0.36772954, 0.3807459...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>328</td>\n",
              "      <td>[[0.29504016, 0.8016512, 0.57202786, 0.1533976...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1617</td>\n",
              "      <td>[[0.45965528, 0.73833716, 0.08573315, 0.530578...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2585</td>\n",
              "      <td>[[0.5110362, 0.4500889, 0.24098411, 0.07690609...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1511</td>\n",
              "      <td>[[0.83730924, 0.25406605, 0.46880996, 0.466190...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1581</td>\n",
              "      <td>[[0.6906224, 0.14458948, 0.48594832, 0.3533352...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2440</td>\n",
              "      <td>[[0.52308756, 0.6332564, 0.104422316, 0.217751...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>944</td>\n",
              "      <td>[[0.2461734, 0.37141222, 0.22389767, 0.2316915...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Number                                           features\n",
              "0     831  [[0.37776634, 0.37836018, 0.082196, 0.2683568,...\n",
              "1     396  [[0.5769105, 0.30342862, 0.15529898, 0.3956436...\n",
              "2    2281  [[0.2971441, 0.35165608, 0.04101849, 0.3135675...\n",
              "3    1779  [[0.61468536, 0.39148712, 0.2238153, 0.2804152...\n",
              "4     518  [[0.45647693, 0.32283726, 0.23408943, 0.260987...\n",
              "5    3746  [[0.13502342, 0.4192431, 0.08697965, 0.2309943...\n",
              "6     472  [[0.64468104, 0.7292648, 0.22713414, 0.3975431...\n",
              "7      80  [[0.58057076, 0.33272293, 0.22853439, 0.198079...\n",
              "8     316  [[0.9567922, 0.12568782, 0.073065616, 0.208439...\n",
              "9    1810  [[0.65189403, 0.24754304, 0.12505412, 0.369573...\n",
              "10    342  [[0.9839933, 0.39295018, 0.16886151, 0.4594364...\n",
              "11   1245  [[0.471568, 0.12150279, 0.06463521, 0.3586164,...\n",
              "12   2871  [[0.39337683, 0.28769162, 0.28371662, 0.569816...\n",
              "13    676  [[0.6500033, 0.021736195, 0.20317031, 0.216475...\n",
              "14   2913  [[0.18810251, 0.57685196, 0.29657072, 0.195130...\n",
              "15   3231  [[0.78989106, 0.4417708, 0.07042155, 0.3457232...\n",
              "16   1883  [[0.6578378, 0.41649896, 0.3062988, 0.23542085...\n",
              "17    952  [[0.49812648, 0.33461848, 0.15921214, 0.261522...\n",
              "18   1443  [[0.38634288, 0.84911853, 0.31505927, 0.402687...\n",
              "19   3108  [[0.37978047, 0.43206847, 0.31043005, 0.256928...\n",
              "20   3324  [[0.7050163, 0.20532523, 0.14971204, 0.2283516...\n",
              "21   1123  [[0.67499614, 0.36101168, 0.04689063, 0.442935...\n",
              "22     50  [[0.45654327, 0.20786308, 0.30018467, 0.509915...\n",
              "23   1802  [[0.8868337, 0.09538166, 0.20751624, 0.2968963...\n",
              "24   3175  [[0.2584805, 0.32244095, 0.15219368, 0.0984607...\n",
              "25    934  [[0.47341016, 0.409316, 0.06726379, 0.17145704...\n",
              "26   1599  [[0.19334601, 0.5033514, 0.36038828, 0.2101330...\n",
              "27   2448  [[0.3886888, 0.036727108, 0.077027924, 0.41263...\n",
              "28   1840  [[0.30242607, 0.46671247, 0.13435742, 0.402290...\n",
              "29   3111  [[0.6123928, 0.1493933, 0.098767206, 0.032874,...\n",
              "30   3730  [[0.27804264, 0.5632236, 0.19547863, 0.2612163...\n",
              "31    189  [[0.71878177, 0.2273899, 0.17426203, 0.3704720...\n",
              "32   3300  [[0.6020217, 0.11465368, 0.36772954, 0.3807459...\n",
              "33    328  [[0.29504016, 0.8016512, 0.57202786, 0.1533976...\n",
              "34   1617  [[0.45965528, 0.73833716, 0.08573315, 0.530578...\n",
              "35   2585  [[0.5110362, 0.4500889, 0.24098411, 0.07690609...\n",
              "36   1511  [[0.83730924, 0.25406605, 0.46880996, 0.466190...\n",
              "37   1581  [[0.6906224, 0.14458948, 0.48594832, 0.3533352...\n",
              "38   2440  [[0.52308756, 0.6332564, 0.104422316, 0.217751...\n",
              "39    944  [[0.2461734, 0.37141222, 0.22389767, 0.2316915..."
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_output['features'][0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj_Q7engWHa-",
        "outputId": "4080417a-51db-46df-d308-a4d71912c340"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37776634"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text_df):\n",
        "  porter = WordNetLemmatizer()\n",
        "  punct = str.maketrans('', '', string.punctuation)\n",
        "  i=0\n",
        "  for description in text_df:\n",
        "    pre_processed_words=[]\n",
        "    words=description.split()\n",
        "    words=[word.lower() for word in words]\n",
        "    words =[word.translate(punct) for word in words]\n",
        "    words=[word for word in words if word.isalpha()]\n",
        "    words=[porter.lemmatize(word) for word in words]\n",
        "    words=[word for word in words if len(word)>1]\n",
        "    words='start '+' '.join(words)+' end'\n",
        "    pre_processed_words.append(words)\n",
        "    text_df[i]=pre_processed_words\n",
        "    i=i+1\n",
        "  return text_df\n",
        "text_dict=preprocess_text(train['Caption'])"
      ],
      "metadata": {
        "id": "6pwJrtwW-mKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdxMoZEq_24l",
        "outputId": "5cb9cf8c-5a98-4b46-9c54-016fe88453ce"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [start no acute cardiopulmonary abnormality end]\n",
              "1            [start no acute cardiopulmonary finding end]\n",
              "2            [start no acute cardiopulmonary disease end]\n",
              "3                                [start normal chest end]\n",
              "4                                [start normal chest end]\n",
              "                              ...                        \n",
              "3209    [start borderline cardiomegaly no acute findin...\n",
              "3210    [start heart size normal tortuous dilated aort...\n",
              "3211         [start xxxx xxxx right pleural effusion end]\n",
              "3212    [start decrease illdefined mixed lucent and op...\n",
              "3213    [start moderate sized right pneumothorax there...\n",
              "Name: Caption, Length: 3214, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_image1 = []\n",
        "train_image2 = []\n",
        "for key in en_output.keys():\n",
        "    train_image1.append(list(en_output[key][0]))\n",
        "    train_image2.append(list(en_output[key][1]))\n",
        "train_text = train.iloc[0:40,]['Clean_capt']"
      ],
      "metadata": {
        "id": "S_tvMjlx7BlO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocab(text_df):\n",
        "  vocab=[]\n",
        "  for key in text_df.keys():\n",
        "    vocab.extend(d.split() for d in text_df[key])\n",
        "  words=[]\n",
        "  for v_list in vocab:\n",
        "    for word in v_list:\n",
        "      words.append(word)\n",
        "  return list(set(words))\n",
        "\n",
        "vocab=create_vocab(text_dict)\n",
        "vocab_size=len(vocab)\n",
        "\n",
        "print('Vocabulary = %d' % (len(vocab)))\n",
        "\n",
        "ixtoword = {}\n",
        "wordtoix = {}\n",
        "ix = 1\n",
        "for w in vocab:\n",
        "    wordtoix[w] = ix\n",
        "    ixtoword[ix] = w\n",
        "    ix += 1\n",
        "\n",
        "vocab_size = len(ixtoword) + 1\n",
        "\n",
        "all_desc = list()\n",
        "for text in text_dict:\n",
        "    text=str(text)\n",
        "    all_desc.append(text)\n",
        "lines = all_desc\n",
        "max_length = max(len(d.split()) for d in lines)\n",
        "\n",
        "print('Description Length: %d' % max_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dApckpwAKfq",
        "outputId": "b5333ae7-02d0-4a64-96ba-4ded08b7a5fd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary = 1353\n",
            "Description Length: 125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_to_index(text_df):\n",
        "  lines = []\n",
        "  for key in text_df.keys():\n",
        "    [lines.append(d) for d in text_df[key]]\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return(tokenizer.word_index)\n",
        "  \n",
        "word2index=word_to_index(text_dict)\n",
        "idx2word = dict([(value, key) for key, value \\\n",
        "                 in word2index.items()]) \n"
      ],
      "metadata": {
        "id": "h3KmFVCMBedg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index"
      ],
      "metadata": {
        "id": "6o-0kFL4E4P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8',\\\n",
        "                  newline='\\n', errors='ignore')\n",
        "    embedding = dict()\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        embedding[tokens[0]] = np.array(tokens[1:],\\\n",
        "                                        dtype='float32')\n",
        "    return embedding\n",
        "embedding=load_vectors('/content/gdrive/MyDrive/Colab Notebooks/wiki.simple.vec')\n",
        "\n",
        "def fastText(embedding):\n",
        "  embedding_dim = 300\n",
        "  embedding_matrix = np.zeros((vocab_size+1, \\\n",
        "                               embedding_dim))\n",
        "  for word, i in word2index.items():\n",
        "      embedding_vector = embedding.get(word)\n",
        "      if embedding_vector is not None:\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix,embedding_dim\n",
        "\n",
        "fastText(embedding)\n",
        "embedding_matrix,embedding_dim=fastText(embedding)"
      ],
      "metadata": {
        "id": "yVQl7JwmCPMw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OgKnyM8FsdW",
        "outputId": "0a6fd817-6373-410e-f289-18f81f89772a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1355, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p5LZcfzGqAG",
        "outputId": "d1c56a13-0fb4-41d8-a3d7-4728137ca471"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [start no acute cardiopulmonary abnormality end]\n",
              "1            [start no acute cardiopulmonary finding end]\n",
              "2            [start no acute cardiopulmonary disease end]\n",
              "3                                [start normal chest end]\n",
              "4                                [start normal chest end]\n",
              "                              ...                        \n",
              "3209    [start borderline cardiomegaly no acute findin...\n",
              "3210    [start heart size normal tortuous dilated aort...\n",
              "3211         [start xxxx xxxx right pleural effusion end]\n",
              "3212    [start decrease illdefined mixed lucent and op...\n",
              "3213    [start moderate sized right pneumothorax there...\n",
              "Name: Caption, Length: 3214, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_data(text_values,max_length,vocab_size):\n",
        "  X1,X2,y=list(),list(),list()\n",
        "  for i in range(0,len(text_values)):\n",
        "    for line in str(text_values[i]):\n",
        "      numeric_seq = [word2index[word] for word in line.split()\\\n",
        "                     if word in word2index]\n",
        "    for ii in range(1,len(numeric_seq)):\n",
        "      in_seq,out_seq=numeric_seq[:ii],numeric_seq[ii]\n",
        "      in_seq=pad_sequences([in_seq],maxlen=max_length,\\\n",
        "                           padding='post')[0]\n",
        "      out_seq=to_categorical([out_seq],num_classes=vocab_size+1)[0]\n",
        "      X2.append(in_seq)\n",
        "      y.append(out_seq)\n",
        "      X1.append(en_output['Number'][i])\n",
        "\n",
        "  return (X1),(X2),(y)\n",
        "\n",
        "X1,X2,y=create_train_data(text_dict,max_length,vocab_size)"
      ],
      "metadata": {
        "id": "aeZRGCfVF4iR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=8\n",
        "step_per_epoch=len(X1)//batch_size\n",
        "epoch=30\n",
        "\n",
        "def data_generator(X1,X2,y,batch_size,epoch,\\\n",
        "                   step_size,max_len,vocab_size):\n",
        "  for j in range(0,epoch):\n",
        "    for k in range(0,step_size):      \n",
        "      for offset in range(0, len(X1), batch_size):\n",
        "        batch_X1,batchX2,batchY=list(),list(),list()\n",
        "        start_index=offset\n",
        "        end_index=offset+batch_size\n",
        "        for i in X1[start_index:end_index]:\n",
        "          batch_X1.append(en_output[i][0][0])\n",
        "        batchX2,batchY=X2[start_index:end_index],\\\n",
        "        y[start_index:end_index]\n",
        "        yield [np.array(batch_X1),np.array(batchX2)],\\\n",
        "        np.array(batchY)\n",
        "        \n",
        "train_gen=data_generator(X1,X2,y,batch_size,epoch,\\\n",
        "                         step_per_epoch,max_length,vocab_size)"
      ],
      "metadata": {
        "id": "2tQJCf0YHA7j"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image \n",
        "input_img = Input(shape=(4096,))\n",
        "feature_img1 = Dropout(0.5)(input_img)\n",
        "feature_img2 = Dense(256, activation='relu')(feature_img1)\n",
        "\n",
        "#text\n",
        "inputs_text = Input(shape=(max_length,))\n",
        "feature_text1 = Embedding(vocab_size+1,embedding_dim,name='embedding_layer')(inputs_text)\n",
        "feature_text2 = Dropout(0.5)(feature_text1)\n",
        "feature_text3 = tf.keras.layers.GRU(256)(feature_text2)\n",
        "\n",
        "#Concat\n",
        "decoder1 = tf.keras.layers.Add()([feature_img2, feature_text3])\n",
        "batch_norm= tf.keras.layers.BatchNormalization(momentum=0.99, epsilon=0.001)(decoder1)\n",
        "decoder2 = Dense(256, activation='relu')(batch_norm)\n",
        "outputs = Dense(vocab_size+1, activation='softmax')(decoder2)\n",
        "\n",
        "model = Model(inputs=[input_img, inputs_text], outputs=outputs)\n",
        "model.get_layer('embedding_layer').set_weights([embedding_matrix])\n",
        "model.get_layer('embedding_layer').trainable = False\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',\\\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "filepath = 'ImageCaptioningModel.h5'\n",
        "#checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', save_best_only=True,mode='min')\n",
        "\n",
        "model.fit(train_gen, epochs=10, steps_per_epoch=100, \n",
        "          #callbacks=[checkpoint],\n",
        "          verbose=1)\n",
        "model.save_weights('/content/gdrive/MyDrive/Colab Notebooks/ImageCaptioningWeights.hdf5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "Lx5DsLTmIcxI",
        "outputId": "e3b88eee-6825-475a-b518-bb8f90e2cbf5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_33 (InputLayer)          [(None, 125)]        0           []                               \n",
            "                                                                                                  \n",
            " input_32 (InputLayer)          [(None, 4096)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 125, 300)     406500      ['input_33[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)           (None, 4096)         0           ['input_32[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)           (None, 125, 300)     0           ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 256)          1048832     ['dropout_29[0][0]']             \n",
            "                                                                                                  \n",
            " gru_13 (GRU)                   (None, 256)          428544      ['dropout_30[0][0]']             \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 256)          0           ['dense_35[0][0]',               \n",
            "                                                                  'gru_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_198 (Batch  (None, 256)         1024        ['add_11[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_36 (Dense)               (None, 256)          65792       ['batch_normalization_198[0][0]']\n",
            "                                                                                                  \n",
            " dense_37 (Dense)               (None, 1355)         348235      ['dense_36[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,298,927\n",
            "Trainable params: 1,891,915\n",
            "Non-trainable params: 407,012\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-be89416506a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m model.fit(train_gen, epochs=10, steps_per_epoch=100, \n\u001b[1;32m     28\u001b[0m           \u001b[0;31m#callbacks=[checkpoint],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           verbose=1)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Colab Notebooks/ImageCaptioningWeights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    861\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search(model,photo,vocab,max_len):\n",
        "  output_text='start'\n",
        "  while True:\n",
        "    seq=[word2index[str(i)] for i in output_text.split()]\n",
        "    seq=pad_sequences([seq],maxlen=max_len,padding='post')\n",
        "    seq=np.array(seq[0])\n",
        "    y_predict=model.predict([np.expand_dims(photo,axis=0),\\\n",
        "                             np.expand_dims(seq,axis=0)])\n",
        "    output_text=output_text+' '+ idx2word[np.argmax(y_predict[0])]\n",
        "    if (len(output_text.split())>max_len) or \\\n",
        "    ((idx2word[np.argmax(y_predict[0])]) == 'end'):\n",
        "      break\n",
        "  output_text=output_text.split()\n",
        "  final_text=[' '.join(output_text[1:-1])]\n",
        "  return final_text    "
      ],
      "metadata": {
        "id": "v5dFtuOKY3ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image1[0]"
      ],
      "metadata": {
        "id": "lZgBeYxM5yRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = train.iloc[0:20,]  ### using all test data instead\n",
        "X_train_img = c['Number']  \n",
        "y_train_rep = c['Clean_capt']\n"
      ],
      "metadata": {
        "id": "JOsRpUX_U3cZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(id_, report):\n",
        "    '''Loads the Image Features with their corresponding Ids'''\n",
        "    img_feature = en_output[id_][0]\n",
        "    return img_feature, report"
      ],
      "metadata": {
        "id": "KmSHrURfU5rG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_img, y_train_rep))\n",
        "train_dataset = train_dataset.map(lambda item1, item2: tf.numpy_function(load_image, [item1, item2],\n",
        "                          [tf.float32, tf.string]),\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "AdjIeCzKVpsZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(2048), name='Image_1')\n",
        "dense1 = Dense(256, kernel_initializer=tf.keras.initializers.glorot_uniform(seed = 56),\n",
        "               name='dense_encoder')(input1)\n",
        "\n",
        "input2 = Input(shape=(155), name='Text_Input')\n",
        "emb_layer = Embedding(input_dim = vocab_size, output_dim = 300, input_length=155, mask_zero=True,\n",
        "                      trainable=False, name=\"Embedding_layer\") ##weights=[embedding_matrix], \n",
        "emb = emb_layer(input2)\n",
        "LSTM2 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
        "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
        "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
        "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")\n",
        "LSTM2_output = LSTM2(emb)\n",
        "dropout1 = Dropout(0.5, name='dropout1')(LSTM2_output)\n",
        "\n",
        "dec =  tf.keras.layers.Add()([dense1, dropout1])\n",
        "\n",
        "fc1 = Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.he_normal(seed = 63),\n",
        "            name='fc1')\n",
        "fc1_output = fc1(dec)\n",
        "output_layer = Dense(vocab_size, activation='softmax', name='Output_layer')\n",
        "output = output_layer(fc1_output)\n",
        "\n",
        "encoder_decoder = Model(inputs = [input1, input2], outputs = output)"
      ],
      "metadata": {
        "id": "RJWRsCMEV0jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras"
      ],
      "metadata": {
        "id": "cg6T8GlsYL5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(2048), name='Image_1')\n",
        "dense1 = Dense(256, kernel_initializer=tf.keras.initializers.glorot_uniform(seed = 56),\n",
        "               name='dense_encoder')(input1)\n",
        "\n",
        "input2 = Input(shape=(155), name='Text_Input')\n",
        "emb_layer = Embedding(input_dim = vocab_size, output_dim = 300, input_length=155, mask_zero=True,\n",
        "                      trainable=False, name=\"Embedding_layer\") ##weights=[embedding_matrix], \n",
        "emb = emb_layer(input2)\n",
        "\n",
        "LSTM2 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
        "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
        "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
        "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")\n",
        "\n",
        "LSTM2_output = LSTM2(emb)\n",
        "dropout1 = Dropout(0.5, name='dropout1')(LSTM2_output)\n",
        "\n",
        "dec =  tf.keras.layers.Add()([dense1, dropout1])\n",
        "\n",
        "fc1 = Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.he_normal(seed = 63),\n",
        "            name='fc1')\n",
        "fc1_output = fc1(dec)\n",
        "output_layer = Dense(vocab_size, activation='softmax', name='Output_layer')\n",
        "output = output_layer(fc1_output)\n",
        "encoder_decoder = Model(inputs = [input1, input2], outputs = output)\n"
      ],
      "metadata": {
        "id": "I9VIZwh5a4Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "65H0owtQY01N"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_node1 = ak.ImageInput()\n",
        "output_node1 = ak.Normalization()(input_node1)\n",
        "output_node1 = ak.ImageAugmentation()(output_node1)\n",
        "output_node1 = ak.ResNetBlock(version=\"v2\")(output_node1)\n",
        "\n",
        "input_node2 = ak.ImageInput()\n",
        "output_node2 = ak.Normalization()(input_node2)\n",
        "output_node2 = ak.ImageAugmentation()(output_node2)\n",
        "#output_node1 = ak.ConvBlock()(output_node)\n",
        "output_node2 = ak.ResNetBlock(version=\"v2\")(output_node2)\n",
        "\n",
        "output_node1 = ak.Merge()([output_node1, output_node2])\n",
        "\n",
        "\n",
        "input_node3 = ak.TextInput()\n",
        "output_node3 = ak.TextToIntSequence()(input_node3)\n",
        "output_node3 = ak.Embedding(pretraining='glove',embedding_dim=200)(output_node3)\n",
        "# Use separable Conv layers in Keras.\n",
        "output_node3 = ak.ConvBlock(separable=True)(output_node3)\n",
        "# output_node3 = ak.ClassificationHead()(output_node3)\n",
        "\n",
        "\n",
        "output_node = ak.Merge()([output_node1, output_node3])\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "\n",
        "auto_model = ak.AutoModel(inputs=[input_node1, input_node2, input_node3],outputs=output_node,overwrite=True,max_trials=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "g-GUubL8WvdM",
        "outputId": "e96769d5-ac58-4bee-b2d4-f89d877e8f61"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-d81d8329a97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0moutput_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassificationHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mauto_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_node1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_node2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_node3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_node\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, project_name, max_trials, directory, objective, tuner, overwrite, seed, max_model_size, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mmax_model_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_model_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/tuners/greedy.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_trials, initial_hps, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mallow_new_entries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_new_entries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Save or load the HyperModel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/graph.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_io_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/graph.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblocks_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         nodes = {\n\u001b[1;32m    190\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnodes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/graph.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblocks_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         nodes = {\n\u001b[1;32m    190\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnodes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/blocks/__init__.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/blocks/basic.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    868\u001b[0m             {\n\u001b[1;32m    869\u001b[0m                 \u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                 \u001b[0;34m\"pretraining\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m                 \u001b[0;34m\"embedding_dim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;34m\"dropout\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_config'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rDQVkf98PvC",
        "outputId": "2fa22fb3-74da-4173-81de-5559c5ac1f91"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autokeras.auto_model.AutoModel at 0x7f13ddc5bfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_model.fit(\n",
        "    [train_image1,train_image2,train_text],\n",
        "    train_text,\n",
        "    batch_size=32,\n",
        "    epochs=3,verbose=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "b2pyBajy8Qcm",
        "outputId": "d067f86c-15b1-4d1a-bec2-863171363a5c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-9d2a075ed97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         dataset, validation_data = self._convert_to_dataset(\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         )\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_analyze_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36m_convert_to_dataset\u001b[0;34m(self, x, y, validation_data, batch_size)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Convert training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36m_check_data_format\u001b[0;34m(self, dataset, validation, predict)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;34m\"Expected x{in_val} to have {input_num} arrays, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \"but got {data_num}\".format(\n\u001b[0;32m--> 344\u001b[0;31m                     \u001b[0min_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 )\n\u001b[1;32m    346\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected x to have 3 arrays, but got 81921"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2],[3,4]])\n",
        "y = np.expand_dims(x, axis=0)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JozdctBvgVRO",
        "outputId": "b7b694f4-1fe8-45da-c92f-e5abc41b3190"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 2],\n",
              "        [3, 4]]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AuZeCxhygdxH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}